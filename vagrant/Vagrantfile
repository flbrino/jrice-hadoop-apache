# -*- mode: ruby -*-
# vi: set ft=ruby :

# All Vagrant configuration is done below. 
Vagrant.configure(2) do |config|
  # The most common configuration options are documented and commented below.
  # For a complete reference, please see the online documentation at
  # https://docs.vagrantup.com.

  # Every Vagrant development environment requires a box. You can search for
  # boxes at https://atlas.hashicorp.com/search.
  config.vm.box = "ubuntu/trusty64"

  config.vm.provider :virtualbox do |vb|
    vb.name = "JRice Hadoop Sandbox - Apache"
    vb.customize ["modifyvm", :id, "--memory", "8192"]
    vb.customize ["modifyvm", :id, "--cpus", "2"]
  end

  # -----------------------------------------------------------------------------------------------------------------------------------------------
  # Define the default values
  #
  # These values will be used if the user has not provided an override environment variable.
  # -----------------------------------------------------------------------------------------------------------------------------------------------
  #define default values for environment variables
  
  local_git_projects_dir = "C:/git/pentaho"
  local_maven_conf_dir = "C:/dev-home/build/maven/apache-maven-3.5.0/conf"
  local_maven_repo_dir = "C:/Users/jrice/.m2"
  local_share_dir = "C:/Users/jrice/dev-env/pentaho/share-hadoop"
  local_ael_dir = "C:/ael"
  local_pentaho_dir = "C:/dev"
  
  vm_git_projects_dir = "/home/vagrant/git"
  vm_maven_conf_dir = "/home/vagrant/workspace/maven/conf"
  vm_maven_repo_dir = "/home/vagrant/.m2"
  vm_share_dir = "/home/vagrant/share"
  vm_ael_dir = "/home/vagrant/ael"
  vm_pentaho_dir = "/home/vagrant/pentaho"
  
  
  # -----------------------------------------------------------------------------------------------------------------------------------------------
  # Set Variables to be used for local machines and hadoop VMs.
  # -----------------------------------------------------------------------------------------------------------------------------------------------
  
  # -----------------------------------------------------------------------------------------------------------------------------------------------
  # Export the environment variables to the hadoop sandbox VM.
  # -----------------------------------------------------------------------------------------------------------------------------------------------
  config.vm.provision :shell, inline: "rm -f /etc/profile.d/hadoop-env-vars.sh", run: "always"
  config.vm.provision :shell, inline: "> /etc/profile.d/hadoop-env-vars.sh", run: "always"
  config.vm.provision :shell, inline: "echo \"export JAVA_HOME=/usr/lib/jvm/java-8-oracle\" >> /etc/profile.d/hadoop-env-vars.sh", run: "always"
  config.vm.provision :shell, inline: "echo \"export HADOOP_HOME=/opt/hadoop-2.8.1\" >> /etc/profile.d/hadoop-env-vars.sh", run: "always"

  config.vm.provision :shell, inline: "echo \"export HADOOP_EXAMPLES=$HADOOP_HOME/share/hadoop/mapreduce\" >> /etc/profile.d/hadoop-env-vars.sh", run: "always"

  config.vm.provision :shell, inline: "echo \"export PIG_HOME=/opt/pig-0.17.0\" >> /etc/profile.d/hadoop-env-vars.sh", run: "always"
  config.vm.provision :shell, inline: "echo \"export PIG_CLASSPATH=$HADOOP_HOME/etc/hadoop/\" >> /etc/profile.d/hadoop-env-vars.sh", run: "always"
  
  config.vm.provision :shell, inline: "echo \"export HIVE_HOME=/opt/apache-hive-2.3.2-bin\" >> /etc/profile.d/hadoop-env-vars.sh", run: "always"
  config.vm.provision :shell, inline: "echo \"export HIVE_CLASSPATH=$HADOOP_HOME/etc/hadoop/\" >> /etc/profile.d/hadoop-env-vars.sh", run: "always"
  
  config.vm.provision :shell, inline: "echo \"export SPARK_HOME=/opt/spark-2.2.0-bin-hadoop2.7\" >> /etc/profile.d/hadoop-env-vars.sh", run: "always"
  
  config.vm.provision :shell, inline: "echo \"export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PIG_HOME/bin:$HIVE_HOME/bin:$SPARK_HOME/bin:$SPARK_HOME/sbin:/home/vagrant/scripts:/home/vagrant/scripts/ael\" >> /etc/profile.d/hadoop-env-vars.sh", run: "always"

  # -----------------------------------------------------------------------------------------------------------------------------------------------
  # Set up synced folders between local machine and dev-env VM.
  # -----------------------------------------------------------------------------------------------------------------------------------------------
  config.vm.synced_folder "scripts", "/home/vagrant/scripts", create: true
  config.vm.synced_folder "config-files", "/home/vagrant/config-files", create: true
  config.vm.synced_folder "provision ", "/home/vagrant/provision", create: true
  
  config.vm.synced_folder "#{local_git_projects_dir}", "#{vm_git_projects_dir}", create: true
  config.vm.synced_folder "#{local_maven_conf_dir}", "#{vm_maven_conf_dir}", create: true
  config.vm.synced_folder "#{local_maven_repo_dir}", "#{vm_maven_repo_dir}", create: true
  config.vm.synced_folder "#{local_share_dir}", "#{vm_share_dir}", create: true
  config.vm.synced_folder "#{local_ael_dir}", "#{vm_ael_dir}", create: true
  config.vm.synced_folder "#{local_pentaho_dir}", "#{vm_pentaho_dir}", create: true
  
  # -----------------------------------------------------------------------------------------------------------------------------------------------
  # Run Provision scripts to setup Java 8 and hadoop apps.
  # -----------------------------------------------------------------------------------------------------------------------------------------------
  config.vm.provision :shell, inline: 'wget --no-check-certificate https://github.com/aglover/ubuntu-equip/raw/master/equip_java8.sh && bash equip_java8.sh'
  config.vm.provision "shell", path: "provision/setup-env.sh"
  config.vm.provision "shell", path: "provision/install-hadoop.sh"
  config.vm.provision "shell", path: "provision/install-hive.sh"
  config.vm.provision "shell", path: "provision/install-pig.sh"
  config.vm.provision "shell", path: "provision/install-spark.sh"
  config.vm.provision "shell", path: "provision/configure-hadoop.sh"
  config.vm.provision "shell", path: "provision/configure-spark.sh"
  config.vm.provision "shell", path: "provision/configure-ael.sh"
  config.vm.provision "shell", path: "provision/format-hdfs.sh"
  config.vm.provision "shell", path: "scripts/start-hadoop-hdfs.sh", run: "always"
  config.vm.provision "shell", path: "provision/create-hdfs-directories-for-mapreduce-history.sh"
  config.vm.provision "shell", path: "provision/create-hdfs-directories-for-hive.sh"
  config.vm.provision "shell", path: "provision/create-hdfs-directories-for-spark-history.sh"
  config.vm.provision "shell", path: "provision/create-hdfs-directories-for-ael.sh"
  config.vm.provision "shell", path: "provision/set-hdfs-directory-permissions.sh"
  config.vm.provision "shell", path: "scripts/start-hadoop-yarn.sh", run: "always"
  config.vm.provision "shell", path: "scripts/start-spark-history-server.sh", run: "always"

  # -----------------------------------------------------------------------------------------------------------------------------------------------
  # Expose ports of Hadoop web apps and services.
  # -----------------------------------------------------------------------------------------------------------------------------------------------

  # HDFS
  config.vm.network "forwarded_port", guest: 9000, host: 9000 
  
  # Name Node Web UI
  config.vm.network "forwarded_port", guest: 50070, host: 50070 
  config.vm.network "forwarded_port", guest: 50470, host: 50470 
  
  # Name Node Metadata Service
  config.vm.network "forwarded_port", guest: 8020, host: 8020 
  config.vm.network "forwarded_port", guest: 50075, host: 50075 
 
  # Yarn Resource Manager
  config.vm.network "forwarded_port", guest: 8032, host: 8032 
  config.vm.network "forwarded_port", guest: 8088, host: 8088 
  
  # Spark Context Web UI
  config.vm.network "forwarded_port", guest: 4040, host: 4040 
  
  # Spark History Server Web UI
  config.vm.network "forwarded_port", guest: 18080, host: 18080 
  
  # -----------------------------------------------------------------------------------------------------------------------------------------------
  # Expose ports of Pentaho apps and services.
  # -----------------------------------------------------------------------------------------------------------------------------------------------
  # Pentaho AEL
  config.vm.network "forwarded_port", guest: 53000, host: 53000 
  config.vm.network "forwarded_port", guest: 53001, host: 53001
  config.vm.network "forwarded_port", guest: 53002, host: 53002 
  config.vm.network "forwarded_port", guest: 53003, host: 53003
  config.vm.network "forwarded_port", guest: 53004, host: 53004 
  config.vm.network "forwarded_port", guest: 53005, host: 53005 
  config.vm.network "forwarded_port", guest: 53006, host: 53006 
  config.vm.network "forwarded_port", guest: 53007, host: 53007
  config.vm.network "forwarded_port", guest: 53008, host: 53008 
  config.vm.network "forwarded_port", guest: 53009, host: 53009
  config.vm.network "forwarded_port", guest: 53010, host: 53010 
  
   # Pentaho AEL - OSGI
  config.vm.network "forwarded_port", guest: 9051, host: 9051 
  
  # -----------------------------------------------------------------------------------------------------------------------------------------------
  # Expose 10 general purpose ports between from dev vm to local.
  #
  # These ports are exposed so you can run 10 arbitrary apps in dev vm and 
  # expose the ports to local machine without having to touch any configuration.
  # -----------------------------------------------------------------------------------------------------------------------------------------------
  config.vm.network "forwarded_port", guest: 7070, host: 7070
  config.vm.network "forwarded_port", guest: 7170, host: 7170
  config.vm.network "forwarded_port", guest: 7270, host: 7270
  config.vm.network "forwarded_port", guest: 7370, host: 7370
  config.vm.network "forwarded_port", guest: 7470, host: 7470
  config.vm.network "forwarded_port", guest: 7570, host: 7570
  config.vm.network "forwarded_port", guest: 7670, host: 7670
  config.vm.network "forwarded_port", guest: 7770, host: 7770
  config.vm.network "forwarded_port", guest: 7870, host: 7870
  config.vm.network "forwarded_port", guest: 7970, host: 7970

end
